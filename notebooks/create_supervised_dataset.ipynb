{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from job_shop_lib.dispatching.feature_observers import (\n",
    "    FeatureObserverType,\n",
    ")\n",
    "from job_shop_lib.graphs import build_resource_task_graph\n",
    "from job_shop_lib.reinforcement_learning import (\n",
    "    SingleJobShopGraphEnv,\n",
    "    ResourceTaskGraphObservation,\n",
    "    get_optimal_actions,\n",
    ")\n",
    "from job_shop_lib.dispatching import OptimalOperationsObserver\n",
    "from job_shop_lib import Schedule\n",
    "from gnn_scheduler.utils import get_data_path\n",
    "from gnn_scheduler.data import JobShopData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = get_data_path()\n",
    "schedules_json = json.load(open(DATA_PATH / \"small_random_instances_0.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from job_shop_lib.constraint_programming import ORToolsSolver\n",
    "# from job_shop_lib.generation import GeneralInstanceGenerator\n",
    "# import tqdm\n",
    "\n",
    "# instance_generator = GeneralInstanceGenerator(\n",
    "#     duration_range=(1, 10),\n",
    "#     num_jobs=4,\n",
    "#     num_machines=3,\n",
    "#     iteration_limit=1000,\n",
    "#     seed=42,\n",
    "# )\n",
    "# schedules_json = []\n",
    "# for instance in tqdm.tqdm(instance_generator):\n",
    "#     solver = ORToolsSolver()\n",
    "#     schedule = solver.solve(instance)\n",
    "#     schedules_json.append(schedule.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(schedules_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_observers_types = [\n",
    "    FeatureObserverType.DURATION,\n",
    "    FeatureObserverType.EARLIEST_START_TIME,\n",
    "    FeatureObserverType.IS_SCHEDULED,\n",
    "    FeatureObserverType.POSITION_IN_JOB,\n",
    "    FeatureObserverType.REMAINING_OPERATIONS,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPERATION_FEATURES_TO_NORMALIZE = [\n",
    "    0,  # Duration\n",
    "    1,  # EarliestStartTime\n",
    "    4,  # PositionInJob\n",
    "    5,  # Job duration\n",
    "    6,  # Job earliest start time\n",
    "    9,  # Job remaining operations\n",
    "]\n",
    "MACHINE_FEATURES_TO_NORMALIZE = [\n",
    "    0,  # Duration\n",
    "    1,  # EarliestStartTime\n",
    "    4,  # RemainingOperations\n",
    "]\n",
    "\n",
    "features_to_normalize = {\n",
    "    \"operation\": OPERATION_FEATURES_TO_NORMALIZE,\n",
    "    \"machine\": MACHINE_FEATURES_TO_NORMALIZE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_features(\n",
    "    node_features_dict: dict[str, np.ndarray],\n",
    "    indices_to_normalize: dict[str, list[int]] | None = None,\n",
    "):\n",
    "    if indices_to_normalize is None:\n",
    "        indices_to_normalize = {\n",
    "            \"operation\": np.arange(8),\n",
    "            \"machine\": np.arange(4),\n",
    "        }\n",
    "    for key, indices in indices_to_normalize.items():\n",
    "        # Divide by the maximum value checking for division by zero\n",
    "        max_values = np.max(node_features_dict[key], axis=0)\n",
    "        max_values[max_values == 0] = 1\n",
    "        node_features_dict[key][:, indices] /= max_values[indices]\n",
    "\n",
    "    return node_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map_available_operations_with_ids_to_original_ids(\n",
    "    available_operations_with_ids, original_ids: dict[str, np.ndarray]\n",
    "):\n",
    "    new_ids = []\n",
    "    for operation_id, machine_id, job_id in available_operations_with_ids:\n",
    "        original_operation_id = original_ids[\"operation\"][operation_id]\n",
    "        original_machine_id = original_ids[\"machine\"][machine_id]\n",
    "        new_ids.append((original_operation_id, original_machine_id, job_id))\n",
    "    return new_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 152/100000 [00:06<1:05:47, 25.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m attempts \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m correct_schedule:\n\u001b[0;32m---> 19\u001b[0m     obs, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n",
      "File \u001b[0;32m~/VSCodeProjects/gnn_scheduler/.venv/lib/python3.12/site-packages/job_shop_lib/reinforcement_learning/_resource_task_graph_observation.py:120\u001b[0m, in \u001b[0;36mResourceTaskGraphObservation.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m            (operation_id, machine_id, job_id).\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     observation, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     new_observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation)\n\u001b[1;32m    122\u001b[0m     new_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info(info)\n",
      "File \u001b[0;32m~/VSCodeProjects/gnn_scheduler/.venv/lib/python3.12/site-packages/job_shop_lib/reinforcement_learning/_single_job_shop_graph_env.py:268\u001b[0m, in \u001b[0;36mSingleJobShopGraphEnv.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m        (operation_id, machine_id, job_id).\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mseed, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[0;32m--> 268\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_observation()\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, {\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomposite_observer\u001b[38;5;241m.\u001b[39mcolumn_names,\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable_operations_with_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_available_actions_with_ids()\n\u001b[1;32m    274\u001b[0m     ),\n\u001b[1;32m    275\u001b[0m }\n",
      "File \u001b[0;32m~/VSCodeProjects/gnn_scheduler/.venv/lib/python3.12/site-packages/job_shop_lib/dispatching/_dispatcher.py:267\u001b[0m, in \u001b[0;36mDispatcher.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subscriber \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubscribers:\n\u001b[0;32m--> 267\u001b[0m     \u001b[43msubscriber\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/VSCodeProjects/gnn_scheduler/.venv/lib/python3.12/site-packages/job_shop_lib/graphs/graph_updaters/_graph_updater.py:52\u001b[0m, in \u001b[0;36mGraphUpdater.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resets the job shop graph.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_shop_graph \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_job_shop_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:201\u001b[0m, in \u001b[0;36m_deepcopy_tuple\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deepcopy_tuple\u001b[39m(x, memo, deepcopy\u001b[38;5;241m=\u001b[39mdeepcopy):\n\u001b[0;32m--> 201\u001b[0m     y \u001b[38;5;241m=\u001b[39m [\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x]\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m# We're not going to put the tuple in the memo, but it's still important we\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# check for it, in case the tuple contains recursive mutable structures.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:162\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:259\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 259\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    261\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:136\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    134\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:221\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    219\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 221\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:167\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n\u001b[1;32m    166\u001b[0m     memo[d] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m--> 167\u001b[0m     \u001b[43m_keep_alive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Make sure x lives at least as long as d\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m/usr/lib/python3.12/copy.py:231\u001b[0m, in \u001b[0;36m_keep_alive\u001b[0;34m(x, memo)\u001b[0m\n\u001b[1;32m    227\u001b[0m d[types\u001b[38;5;241m.\u001b[39mMethodType] \u001b[38;5;241m=\u001b[39m _deepcopy_method\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m d\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_keep_alive\u001b[39m(x, memo):\n\u001b[1;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Keeps a reference to the object x in the memo.\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Because we remember objects by their id, we have\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    the memo itself...\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = {}\n",
    "for schedule_dict in tqdm.tqdm(schedules_json):\n",
    "    observations = []\n",
    "    action_probabilities_sequence = []\n",
    "    schedule = Schedule.from_dict(**schedule_dict)\n",
    "    graph = build_resource_task_graph(schedule.instance)\n",
    "    env = SingleJobShopGraphEnv(\n",
    "        graph,\n",
    "        feature_observer_configs=features_observers_types,\n",
    "        ready_operations_filter=None,\n",
    "    )\n",
    "    env = ResourceTaskGraphObservation(env)\n",
    "    optimal_ops_observer = OptimalOperationsObserver(\n",
    "        env.unwrapped.dispatcher, schedule\n",
    "    )\n",
    "    correct_schedule = False\n",
    "    attempts = 0\n",
    "    while not correct_schedule:\n",
    "        obs, info = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "\n",
    "            action_probs = get_optimal_actions(\n",
    "                optimal_ops_observer,\n",
    "                _map_available_operations_with_ids_to_original_ids(\n",
    "                    info[\"available_operations_with_ids\"],\n",
    "                    obs[\"original_ids_dict\"],\n",
    "                ),\n",
    "            )\n",
    "            if len(action_probs) > 1:\n",
    "                obs[\"node_features_dict\"] = _normalize_features(\n",
    "                    obs[\"node_features_dict\"]\n",
    "                )\n",
    "                observations.append(obs)\n",
    "                action_probs_adjusted = {}\n",
    "                assert len(info[\"available_operations_with_ids\"]) == len(\n",
    "                    action_probs\n",
    "                )\n",
    "                for key, value in zip(\n",
    "                    info[\"available_operations_with_ids\"], action_probs.values()\n",
    "                ):\n",
    "                    action_probs_adjusted[key] = value\n",
    "                action_probabilities_sequence.append(action_probs_adjusted)\n",
    "            if max(action_probs.values()) != 1.0:\n",
    "                correct_schedule = False\n",
    "                break\n",
    "            optimal_actions = [\n",
    "                action\n",
    "                for action, value in action_probs.items()\n",
    "                if value == 1.0\n",
    "            ]\n",
    "            action_choice = random.choice(optimal_actions)\n",
    "            _, machine_id, job_id = action_choice\n",
    "            # machine_id = obs[\"original_ids_dict\"][\"machine\"][machine_id]\n",
    "            obs, reward, done, _, info = env.step((job_id, machine_id))\n",
    "        makespan = env.unwrapped.dispatcher.schedule.makespan()\n",
    "        correct_schedule = makespan == schedule.makespan()\n",
    "        if not correct_schedule:\n",
    "            attempts += 1\n",
    "            name = schedule.instance.name\n",
    "            print(f\"Failed to generate correct schedule for {name}\")\n",
    "            print(f\"Attempt {attempts}\")\n",
    "            if attempts >= 100:\n",
    "                raise ValueError(\"Failed to generate correct schedule\")\n",
    "    dataset[schedule.instance.name] = (\n",
    "        observations,\n",
    "        action_probabilities_sequence,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = []\n",
    "action_probabilities_sequence = []\n",
    "for obs, action_probs in dataset.values():\n",
    "    observations.extend(obs)\n",
    "    action_probabilities_sequence.extend(action_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3093it [00:00, 3325.14it/s]\n"
     ]
    }
   ],
   "source": [
    "hetero_dataset = []\n",
    "for obs, action_probs in tqdm.tqdm(\n",
    "    zip(observations, action_probabilities_sequence)\n",
    "):\n",
    "    job_shop_data = JobShopData()\n",
    "    for key, value in obs.items():\n",
    "        for subkey, subvalue in value.items():\n",
    "            if key == \"node_features_dict\":\n",
    "                job_shop_data[subkey].x = torch.from_numpy(subvalue)\n",
    "            elif key == \"edge_index_dict\":\n",
    "                job_shop_data[subkey].edge_index = torch.from_numpy(subvalue)\n",
    "    job_shop_data[\"y\"] = torch.tensor(\n",
    "        list(action_probs.values()), dtype=torch.float32\n",
    "    )\n",
    "    job_shop_data[\"valid_pairs\"] = torch.tensor(list(action_probs.keys()))\n",
    "    hetero_dataset.append(job_shop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: <class 'torch_geometric.data.storage.NodeStorage'>\n",
      "y: <class 'torch.Tensor'>\n",
      "  Shape: torch.Size([6]), Dtype: torch.float32\n",
      "edge_index: <class 'torch_geometric.data.storage.NodeStorage'>\n",
      "valid_pairs: <class 'torch.Tensor'>\n",
      "  Shape: torch.Size([6, 3]), Dtype: torch.int64\n",
      "\n",
      "Node type: operation\n",
      "  x: Shape torch.Size([30, 8]), Dtype: torch.float32\n",
      "\n",
      "Node type: machine\n",
      "  x: Shape torch.Size([5, 4]), Dtype: torch.float32\n",
      "\n",
      "Node type: x\n",
      "\n",
      "Node type: edge_index\n",
      "\n",
      "Edge type: ('operation', 'to', 'operation')\n",
      "  edge_index: Shape torch.Size([2, 120]), Dtype: torch.int64\n",
      "\n",
      "Edge type: ('operation', 'to', 'machine')\n",
      "  edge_index: Shape torch.Size([2, 30]), Dtype: torch.int64\n",
      "\n",
      "Edge type: ('machine', 'to', 'operation')\n",
      "  edge_index: Shape torch.Size([2, 30]), Dtype: torch.int64\n",
      "\n",
      "Edge type: ('machine', 'to', 'machine')\n",
      "  edge_index: Shape torch.Size([2, 20]), Dtype: torch.int64\n"
     ]
    }
   ],
   "source": [
    "def print_dtypes(data):\n",
    "    \"\"\"Print dtypes of all tensors in a HeteroData object\"\"\"\n",
    "    # Print global attributes\n",
    "    for key in data.keys():\n",
    "        if not isinstance(data[key], (dict, list)):\n",
    "            print(f\"{key}: {type(data[key])}\")\n",
    "            if isinstance(data[key], torch.Tensor):\n",
    "                print(f\"  Shape: {data[key].shape}, Dtype: {data[key].dtype}\")\n",
    "\n",
    "    # Print node attributes\n",
    "    for node_type in data.node_types:\n",
    "        print(f\"\\nNode type: {node_type}\")\n",
    "        for key, value in data[node_type].items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"  {key}: Shape {value.shape}, Dtype: {value.dtype}\")\n",
    "\n",
    "    # Print edge attributes\n",
    "    for edge_type in data.edge_types:\n",
    "        print(f\"\\nEdge type: {edge_type}\")\n",
    "        for key, value in data[edge_type].items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                print(f\"  {key}: Shape {value.shape}, Dtype: {value.dtype}\")\n",
    "\n",
    "\n",
    "# Usage\n",
    "print_dtypes(hetero_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6649],\n",
       "        [-0.0698],\n",
       "        [ 0.3180],\n",
       "        [ 0.6859],\n",
       "        [-0.5058],\n",
       "        [ 0.5251]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gnn_scheduler.model import ResidualSchedulingGNN, HeteroMetadata\n",
    "\n",
    "metadata = HeteroMetadata(node_types=[\"operation\", \"machine\"])\n",
    "\n",
    "\n",
    "model = ResidualSchedulingGNN(\n",
    "    metadata=metadata, in_channels_dict={\"operation\": 8, \"machine\": 4}\n",
    ")\n",
    "\n",
    "model(\n",
    "    hetero_dataset[0].x_dict,\n",
    "    hetero_dataset[0].edge_index_dict,\n",
    "    hetero_dataset[0].valid_pairs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting CUDA_LAUNCH_BLOCKING=1 for debugging\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/VSCodeProjects/gnn_scheduler/.venv/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Training: 100%|██████████| 97/97 [00:04<00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 0.1827 | Accuracy: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.1606 | Accuracy: 0.9296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.1454 | Accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.1331 | Accuracy: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Loss: 0.1209 | Accuracy: 0.9477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:05<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Loss: 0.1166 | Accuracy: 0.9517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Loss: 0.1076 | Accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Loss: 0.0905 | Accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:11<00:00,  8.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Loss: 0.0874 | Accuracy: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:11<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Loss: 0.0906 | Accuracy: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 20.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Loss: 0.0830 | Accuracy: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Loss: 0.0753 | Accuracy: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Loss: 0.0781 | Accuracy: 0.9699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Loss: 0.0657 | Accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Loss: 0.0662 | Accuracy: 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Loss: 0.0547 | Accuracy: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Loss: 0.0551 | Accuracy: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Loss: 0.0527 | Accuracy: 0.9797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Loss: 0.0555 | Accuracy: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Loss: 0.0483 | Accuracy: 0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Loss: 0.0483 | Accuracy: 0.9820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Loss: 0.0442 | Accuracy: 0.9823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Loss: 0.0417 | Accuracy: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Loss: 0.0419 | Accuracy: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Loss: 0.0387 | Accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Loss: 0.0341 | Accuracy: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Loss: 0.0443 | Accuracy: 0.9828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Loss: 0.0346 | Accuracy: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Loss: 0.0330 | Accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:04<00:00, 23.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Loss: 0.0376 | Accuracy: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Loss: 0.0335 | Accuracy: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Loss: 0.0354 | Accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Loss: 0.0303 | Accuracy: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Loss: 0.0285 | Accuracy: 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Loss: 0.0309 | Accuracy: 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Loss: 0.0384 | Accuracy: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97/97 [00:03<00:00, 24.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Loss: 0.0247 | Accuracy: 0.9915\n",
      "Reached high accuracy. Stopping at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "# BCEWithLogitsLoss is used because the model outputs logits\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "loader = DataLoader(hetero_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    loader,\n",
    "    loss_function: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data in tqdm.tqdm(loader, desc=\"Training\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x_dict, data.edge_index_dict, data.valid_pairs)\n",
    "        loss = loss_function(output.squeeze(1), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        pred = torch.sigmoid(output.squeeze(1)) > 0.5\n",
    "        correct += (pred == (data.y > 0.5)).sum().item()\n",
    "        total += len(data.y)\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    loss, accuracy = train(model, loader, loss_function, optimizer, device)\n",
    "    print(f\"Epoch {epoch} | Loss: {loss:.4f} | Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Early stopping could be added here\n",
    "    if accuracy > 0.99:\n",
    "        print(f\"Reached high accuracy. Stopping at epoch {epoch}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3093"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hetero_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(2, 1, 1): 1, (3, 0, 2): 1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"operation\"].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  0],\n",
       "        [ 6,  0,  1],\n",
       "        [10,  4,  2],\n",
       "        [17,  4,  3],\n",
       "        [20,  2,  4],\n",
       "        [26,  4,  5],\n",
       "        [33,  5,  2],\n",
       "        [34,  9,  3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"valid_pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index_dict': {('operation',\n",
       "   'to',\n",
       "   'operation'): array([], shape=(2, 0), dtype=int32),\n",
       "  ('operation',\n",
       "   'to',\n",
       "   'machine'): array([[0, 1, 2],\n",
       "         [2, 1, 0]]),\n",
       "  ('machine',\n",
       "   'to',\n",
       "   'operation'): array([[0, 1, 2],\n",
       "         [2, 1, 0]]),\n",
       "  ('machine',\n",
       "   'to',\n",
       "   'machine'): array([[0, 0, 1, 1, 2, 2],\n",
       "         [1, 2, 0, 2, 0, 1]])},\n",
       " 'node_features_dict': {'operation': array([[  0.85915494,   0.        ,   0.        ,   0.        ,\n",
       "            1.        ,   0.        ,   0.        ,   1.        ],\n",
       "         [  0.7605634 ,   0.        ,   0.        ,   0.        ,\n",
       "            0.8852459 ,   0.        ,   0.        ,   1.        ],\n",
       "         [  1.        , -63.        ,   1.        ,   0.        ,\n",
       "            0.        ,   0.        ,   1.        ,   0.        ]],\n",
       "        dtype=float32),\n",
       "  'machine': array([[   0.       , -302.       ,    1.       ,    0.       ],\n",
       "         [   0.8852459,    0.       ,    0.       ,    1.       ],\n",
       "         [   1.       ,    0.       ,    0.       ,    1.       ]],\n",
       "        dtype=float32)},\n",
       " 'original_ids_dict': {'operation': array([ 3,  7, 11]),\n",
       "  'machine': array([0, 2, 3])}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
